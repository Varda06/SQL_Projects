{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (9.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from a CSV file into a dataframe\n",
    "Dataset Used -  AMAZON SALES/REVIEWS from Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sales.db\"\n",
    "table_name = \"sales_data_7\"\n",
    "df = pd.read_csv('/Users/vardasinghal/Downloads/SQL Projects/amazon.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed string to numeric for actual_price , discounted_price , discount_percentage, rating_count, rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted item as product_bought and top_category from category for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted brand from product name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "#Changing string to numneric\n",
    "df['actual_price'] = df['actual_price'].str.replace('₹','').str.replace(',', '').astype(float)\n",
    "df['discounted_price'] = df['discounted_price'].str.replace('₹','').str.replace(',', '').astype(float)\n",
    "df['discount_percentage'] = df['discount_percentage'].str.replace('%', '').astype(float)\n",
    "df['rating_count'] = df['rating_count'].str.replace(',', '').astype(float)\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "#Retrieving subcategory\n",
    "# Split the 'category' column by '|' and get the last element of each split\n",
    "df['product_bought'] = df['category'].str.split('|').str[-1]\n",
    "df['top_category'] = df['category'].str.split('|').str[0]\n",
    "\n",
    "#Retrieve Brand\n",
    "df['brand'] = df['product_name'].str.split(' ').str[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to a database so that I can use SQL\n",
    "conn = sqlite3.connect(name) #if the db does not exist, this creates a Any_Database_Name.db file in the current directory\n",
    "#store your table in the database:\n",
    "df.to_sql(table_name, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview of data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Overview of Category\n",
    "#2) Top Category by Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category Split\n",
    "get_category = 'SELECT DISTINCT CATEGORY FROM sales_data_7'\n",
    "category_df = pd.read_sql(get_category, conn)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Category by Volume\n",
    "get_category_count = '''\n",
    "SELECT category, \n",
    "COUNT(*) as category_count\n",
    "from sales_data_7\n",
    "group by 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "category_count_df = pd.read_sql(get_category_count, conn)\n",
    "category_count_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought Process:\n",
    "To focus on the final product purchased, I extracted the last item from the category hierarchy, as it contains multiple subcategories. (See Data Preparation for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by Product_Bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What will it answer\n",
    "#1) Product Breakdown by Volume and Revenue\n",
    "#2) Products with Above-Average Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product bought split by volume\n",
    "get_product_count = '''\n",
    "SELECT product_bought , COUNT(*) as product_volume\n",
    "from sales_data_7\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "product_count_df = pd.read_sql(get_product_count, conn)\n",
    "product_count_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Products by Revenue\n",
    "get_product_count_revenue = '''\n",
    "SELECT product_bought, \n",
    "SUM(discounted_price) as total_sales\n",
    "from sales_data_7\n",
    "group by 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "product_count_revenue_df = pd.read_sql(get_product_count_revenue, conn)\n",
    "product_count_revenue_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering products where average price per product is greater than total average sales\n",
    "get_product_average_revenue = '''\n",
    "with cte as\n",
    "(\n",
    "SELECT product_bought, \n",
    "AVG(discounted_price) as avg_product_price\n",
    "from sales_data_7\n",
    "group by 1\n",
    ")\n",
    "SELECT product_bought , avg_product_price\n",
    "FROM CTE\n",
    "WHERE avg_product_price > (SELECT AVG(discounted_price) FROM sales_data_7 )\n",
    "order by 2 desc\n",
    "'''\n",
    "product_average_df = pd.read_sql(get_product_average_revenue, conn)\n",
    "product_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts:\n",
    "I wanted to analyze brand performance across product categories, so I extracted the brand from the product name, as the same brands appear in multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will it answer\n",
    "#1) Top brands by product category \n",
    "#2) Average Brand Rating by Category (with High Sales)\n",
    "#3) Most Popular Brand\n",
    "#4) Brand Loyalty\n",
    "#5) Brand Competition (by Rating) but having similar price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Selling Brand for product_bought(category) based on total revenue\n",
    "get_brand = '''\n",
    "with cte as\n",
    "(\n",
    "select product_bought , brand , product_bought, SUM(discounted_price) as total_sales,\n",
    " DENSE_RANK() OVER (PARTITION BY product_bought ORDER BY SUM(discounted_price) desc) as rnk\n",
    " FROM sales_data_7\n",
    " group by 1 , 2\n",
    ")\n",
    "select product_bought, brand , total_sales\n",
    "from cte \n",
    "where rnk <= 1\n",
    "ORDER BY 3 DESC\n",
    "'''\n",
    "get_brand_by_topproduct = pd.read_sql(get_brand, conn)\n",
    "get_brand_by_topproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average rating for brands where sales(discounted_price) > 50000 across all product_bought(category) and rating frequency > 3\n",
    "get_brand_rating = '''\n",
    "SELECT product_bought,\n",
    "       brand, \n",
    "       AVG(rating) AS avg_rating, \n",
    "       COUNT(*) AS frequency\n",
    "FROM (\n",
    "    SELECT product_bought,\n",
    "           brand,\n",
    "           rating,\n",
    "           discounted_price,\n",
    "           SUM(discounted_price) OVER (PARTITION BY product_bought) AS total_sales\n",
    "    FROM sales_data_7\n",
    ") AS subquery\n",
    "WHERE total_sales > 50000\n",
    "GROUP BY product_bought, brand\n",
    "HAVING COUNT(*) >= 3\n",
    "ORDER BY product_bought,  frequency DESC , avg_rating DESC;\n",
    "'''\n",
    "get_brand_rating = pd.read_sql(get_brand_rating, conn)\n",
    "get_brand_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Most Popular Brand and its category by Review Count\n",
    "get_popular_product = '''\n",
    "SELECT \n",
    "    brand, product_bought,\n",
    "    COUNT(*) AS review_count\n",
    "FROM sales_data_7\n",
    "GROUP BY brand , 2\n",
    "ORDER BY review_count DESC;\n",
    "'''\n",
    "get_popular_product = pd.read_sql(get_popular_product, conn)\n",
    "get_popular_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brand Loyalty showing multiple purchase of same brand per user\n",
    "get_brand_loyal = '''\n",
    "SELECT brand , distinct_products_byuser\n",
    "from\n",
    "(\n",
    "SELECT brand, user_id, COUNT(DISTINCT product_id) AS distinct_products_byuser\n",
    "FROM sales_DATA_7\n",
    "GROUP BY brand, user_id\n",
    "HAVING COUNT(DISTINCT product_id) > 1\n",
    "ORDER BY  distinct_products_byuser DESC\n",
    ") as subquery\n",
    "'''\n",
    "get_brand_loyal = pd.read_sql(get_brand_loyal, conn)\n",
    "get_brand_loyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brands with similar price across product_bought and their rating\n",
    "get_brands_similar_price = '''\n",
    "SELECT DISTINCT\n",
    "    a.product_bought, \n",
    "    a.brand AS brand_1, \n",
    "    a.discounted_price AS discounted_price_1, \n",
    "    a.rating AS rating_1, \n",
    "    b.brand AS brand_2, \n",
    "    b.discounted_price AS discounted_price_2, \n",
    "    b.rating AS rating_2\n",
    "FROM \n",
    "    sales_data_7 AS a\n",
    "JOIN \n",
    "    sales_data_7 AS b\n",
    "    ON a.product_bought = b.product_bought  -- Same product_bought category\n",
    "    AND a.discounted_price = b.discounted_price  -- Same discounted price\n",
    "    AND a.brand != b.brand  -- Different brands\n",
    "ORDER BY \n",
    "    a.product_bought, a.discounted_price;\n",
    "'''\n",
    "get_brands_similar_price  = pd.read_sql(get_brands_similar_price , conn)\n",
    "get_brands_similar_price "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
